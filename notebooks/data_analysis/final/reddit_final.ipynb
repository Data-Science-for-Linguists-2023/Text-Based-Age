{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age Classificaion/Analysis of Text and Age\n",
    "\n",
    "Let's actually start with a classification model, gather the results, and then investigate.\n",
    "\n",
    "Here's the plan for the upcoming work in the notebook --\n",
    "\n",
    "- CountVectorizer (vector representation of text) on N-grams\n",
    "- Train a Naive Bayes Classifier\n",
    "- Look at most significant features\n",
    "- Form hypotheses and iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What happened to my comment....it was soo good...</td>\n",
       "      <td>te</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A shit ton of censorship. And I don't mean \"de...</td>\n",
       "      <td>te</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wasn't aware of the drama between /r/askmen an...</td>\n",
       "      <td>te</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nice username  I too am from Finland</td>\n",
       "      <td>te</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Your comment was on the [other post]( lol</td>\n",
       "      <td>te</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64861</th>\n",
       "      <td>And, after 10 years of marriage, you can get 5...</td>\n",
       "      <td>th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64862</th>\n",
       "      <td>Yes. Thank you for this response. I don’t view...</td>\n",
       "      <td>th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64863</th>\n",
       "      <td>Better hope that you're contacted before someo...</td>\n",
       "      <td>th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64864</th>\n",
       "      <td>Thank you for this question. I also find mysel...</td>\n",
       "      <td>th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64865</th>\n",
       "      <td>Yes. Being able to consider working part-time ...</td>\n",
       "      <td>th</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64866 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text age\n",
       "0      What happened to my comment....it was soo good...  te\n",
       "1      A shit ton of censorship. And I don't mean \"de...  te\n",
       "2      Wasn't aware of the drama between /r/askmen an...  te\n",
       "3                   Nice username  I too am from Finland  te\n",
       "4              Your comment was on the [other post]( lol  te\n",
       "...                                                  ...  ..\n",
       "64861  And, after 10 years of marriage, you can get 5...  th\n",
       "64862  Yes. Thank you for this response. I don’t view...  th\n",
       "64863  Better hope that you're contacted before someo...  th\n",
       "64864  Thank you for this question. I also find mysel...  th\n",
       "64865  Yes. Being able to consider working part-time ...  th\n",
       "\n",
       "[64866 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_pickle('../../../data_samples/reddit_samples/all.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now more or less in it's final form."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the main vectorizer and classifier. We might make changes to these, but for now, we're keeping it all in one place for covenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def train_classifier(texts, labels, ngrams):\n",
    "    # create a CountVectorizer with character-based bigrams\n",
    "    vectorizer = CountVectorizer(analyzer='char', ngram_range=ngrams, lowercase=False, stop_words=None)\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    # train the classifier and return it\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X, labels)\n",
    "    return clf, vectorizer\n",
    "\n",
    "def train_word_classifier(texts, labels):\n",
    "    # create a CountVectorizer with words\n",
    "    vectorizer = CountVectorizer(lowercase=False, stop_words=None)\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    # train the classifier and return it\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X, labels)\n",
    "    return clf, vectorizer\n",
    "\n",
    "def predict_age_group(classifier, vectorizer, new_text):\n",
    "    # take in a classifier as input and return the prediction\n",
    "    new_X = vectorizer.transform([new_text])\n",
    "    predicted_age_group = classifier.predict(new_X)\n",
    "    return predicted_age_group\n",
    "\n",
    "def evaluate_classifier(classifier, vectorizer, test_texts, test_labels):\n",
    "    # transform the test data\n",
    "    X_test = vectorizer.transform(test_texts)\n",
    "    # predict the age group and return score\n",
    "    predicted_age_groups = classifier.predict(X_test)\n",
    "    return accuracy_score(test_labels, predicted_age_groups)\n",
    "\n",
    "\n",
    "def analyze_features(N, clf, vec):\n",
    "    feature_names = list(vec.vocabulary_.keys())\n",
    "    log_prob = clf.feature_log_prob_\n",
    "    top_N_features = []\n",
    "    for i in range(clf.classes_.shape[0]):\n",
    "        top_N_indices = log_prob[i].argsort()[::-1][:N]\n",
    "        top_N_features.extend([feature_names[idx] for idx in top_N_indices])\n",
    "    print(\"Top {} most significant textual features:\".format(N))\n",
    "    print(top_N_features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the analysis in the `../draft/` folder, we have determined that some preprocessing helps, but not all the way (with lowercase, stemming, lemmatizing, etc.). This also helps to an extent to get the non-english text out, or at least, non-english characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_texts(texts):\n",
    "    \"\"\"\n",
    "    Cleans the given text by removing non-English characters and punctuation.\n",
    "    \"\"\"\n",
    "    # Keep only English characters and punctuation\n",
    "    text = [re.sub(r'[^a-zA-Z\\s\\.,?!]', '', text) for text in texts]\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = preprocess_texts(list(data['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What happened to my comment....it was soo good....  so ima just repeat myself  U callin yer selfs D O G S eh?',\n",
       " 'A shit ton of censorship. And I dont mean dem libtards takin muh free spheech kind of censorship. Basically if you disagree with a commenter, and reply stating a counter, your comments will be removed. Or even factual fucking errors are counted as invalidating.  Extreme example   is  and you just got to accept that  Its actually  but i get what youre saying  Your comment was removed for Invalidation.',\n",
       " 'Wasnt aware of the drama between raskmen and rAskWomen, and yet hearing about it now is completely unsurprising.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(data['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['te', 'te', 'te']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a function to drop text that's too short, and if there aren't any alphabetical bits in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def drop_short_text(text, labels, min_length=5):\n",
    "    \"\"\"\n",
    "    Drop elements from `text` and `labels` lists where the length of `text` is less than `min_length`\n",
    "    or where `text` only contains punctuation or is empty\n",
    "    \"\"\"\n",
    "    filtered_text = []\n",
    "    filtered_labels = []\n",
    "    for i in range(len(text)):\n",
    "        if len(text[i]) < min_length or all(char in string.punctuation or char.isspace() for char in text[i]):\n",
    "            # check if text is too short or only contains punctuation or whitespace\n",
    "            continue  # skip to next iteration if true\n",
    "        if not any(c.isalpha() for c in text[i]):\n",
    "            # check if text has at least one alphabet character\n",
    "            continue  # skip to next iteration if false\n",
    "        filtered_text.append(text[i])\n",
    "        filtered_labels.append(labels[i])\n",
    "    return filtered_text, filtered_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64866\n",
      "64866\n"
     ]
    }
   ],
   "source": [
    "print(len(preprocessed))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, labels = drop_short_text(preprocessed, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64507\n",
      "64507\n"
     ]
    }
   ],
   "source": [
    "print(len(text))\n",
    "print(len(labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, looks like we filtered out a good bit. Now, let's split it into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(text, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7052394977522864\n",
      "Top 10 most significant textual features:\n",
      "['Pratchetts', 'knockout', 'skipping', 'combines', 'Urban', 'Hongkonger', 'simulator', 'adjustments', 'OOP', 'savoured', 'Pratchetts', 'knockout', 'skipping', 'combines', 'simulator', 'adjustments', 'Hongkonger', 'Urban', 'savoured', 'dialect', 'Pratchetts', 'knockout', 'skipping', 'combines', 'simulator', 'savoured', 'Urban', 'adjustments', 'dialect', 'Hongkonger']\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on the training data\n",
    "clf, vectorizer = train_word_classifier(train_texts, train_labels)\n",
    "\n",
    "# Evaluate the classifier on the test data\n",
    "accuracy = evaluate_classifier(clf, vectorizer, test_texts, test_labels)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "analyze_features(10, clf, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6013021237017516\n",
      "Top 10 most significant textual features:\n",
      "['dA', 'up', '\\xa0r', 'ca', 'Ax', 'Px', 'Ee', 'OB', '.u', 'su', 'dA', 'up', '\\xa0r', 'ca', 'Ax', 'Px', '.u', 'OB', 'Ee', 'jv', 'dA', 'up', '\\xa0r', 'ca', 'Px', 'Ax', '.u', 'OB', 'Ee', 'su']\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on the training data\n",
    "clf, vectorizer = train_classifier(train_texts, train_labels, (2,2))\n",
    "\n",
    "# Evaluate the classifier on the test data\n",
    "accuracy = evaluate_classifier(clf, vectorizer, test_texts, test_labels)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy:\", accuracy)\n",
    "analyze_features(10, clf, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6686560223221206\n",
      "Top 10 most significant textual features:\n",
      "['! Y', 'GAN', 'vip', 'Thi', 'Tzu', 'ean', 'TOL', 'e,p', 'lfS', 'oo ', '! Y', 'GAN', 'vip', 'e,p', 'Thi', 'TOL', 'Tzu', 'ean', 'lfS', 'lyr', '! Y', 'GAN', 'vip', 'e,p', 'Thi', 'Tzu', 'ean', 'lfS', 'TOL', 'LYR']\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on the training data\n",
    "clf, vectorizer = train_classifier(train_texts, train_labels, (3,3))\n",
    "\n",
    "# Evaluate the classifier on the test data\n",
    "accuracy = evaluate_classifier(clf, vectorizer, test_texts, test_labels)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy:\", accuracy)\n",
    "analyze_features(10, clf, vectorizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.696248643621144\n",
      "Top 10 most significant textual features:\n",
      "['ns t', ' Uno', 'up.c', ' npc', 'YESS', 'heel', 'g, y', 'ue f', 'fo. ', 'qrst', 'ns t', ' Uno', 'up.c', 'heel', ' npc', 'YESS', 'g, y', ' mod', 'ue f', 'fo. ', 'ns t', ' Uno', 'heel', 'up.c', ' npc', 'YESS', 'g, y', 'd I?', 'fo. ', 'ue f']\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on the training data\n",
    "clf, vectorizer = train_classifier(train_texts, train_labels, (4,4))\n",
    "\n",
    "# Evaluate the classifier on the test data\n",
    "accuracy = evaluate_classifier(clf, vectorizer, test_texts, test_labels)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy:\", accuracy)\n",
    "analyze_features(10, clf, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7007440706867153\n",
      "Top 10 most significant textual features:\n",
      "['ay. y', 'A foc', 'rong ', 'sy, a', 'Elize', 'amn n', 't fit', 'CY as', 'te Wa', 'ght h', 'ay. y', 'A foc', 'sy, a', 'rong ', 'Elize', 'ght h', 'try a', 'ned e', 'tucki', 'void.', 'ay. y', 'A foc', 'sy, a', 'rong ', 'ght h', 'Elize', 'try a', 'tucki', 'void.', 'ia an']\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on the training data\n",
    "clf, vectorizer = train_classifier(train_texts, train_labels, (5,5))\n",
    "\n",
    "# Evaluate the classifier on the test data\n",
    "accuracy = evaluate_classifier(clf, vectorizer, test_texts, test_labels)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy:\", accuracy)\n",
    "analyze_features(10, clf, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6982638350643311\n",
      "Top 10 most significant textual features:\n",
      "['he ase', 'f my o', 'ut sim', 'e I sh', 'me st ', 'ly. Ke', 'iroman', 'o pres', ' grann', 'ad pro', 'he ase', 'e I sh', 'me st ', 'ad pro', 'o pres', 'f my o', 'ut sim', 'ns? Li', 'ly. Ke', '.You c', 'he ase', 'e I sh', 'ad pro', 'o pres', 'me st ', 'ut sim', 'f my o', 'ns? Li', 'euroty', 'ge giv']\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on the training data\n",
    "clf, vectorizer = train_classifier(train_texts, train_labels, (6,6))\n",
    "\n",
    "# Evaluate the classifier on the test data\n",
    "accuracy = evaluate_classifier(clf, vectorizer, test_texts, test_labels)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy:\", accuracy)\n",
    "analyze_features(10, clf, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6902030692915827\n",
      "Top 10 most significant textual features:\n",
      "[' two fr', 'generat', 'hat , w', 'red wor', ' say pp', ' lmao n', 'op. Im ', 'ilure. ', ' good P', 'l. some', 'generat', ' two fr', 'red wor', 'y Manag', 're a gr', ' say pp', ' i assu', 'l. some', 'h STDs ', ' lmao n', 'generat', 'irl, th', 'lex I k', ' two fr', 'y Manag', 'a. she ', 'red wor', 're a gr', 'accddsu', 'per fri']\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on the training data\n",
    "clf, vectorizer = train_classifier(train_texts, train_labels, (7,7))\n",
    "\n",
    "# Evaluate the classifier on the test data\n",
    "accuracy = evaluate_classifier(clf, vectorizer, test_texts, test_labels)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy:\", accuracy)\n",
    "analyze_features(10, clf, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6788869942644551\n",
      "Top 10 most significant textual features:\n",
      "['e. The d', 'are on y', 'f is alw', 'the endo', ' way so ', ' over in', 'en I get', 'h. Just ', 'grey are', 't. I cur', 'e. The d', 'the endo', ' over in', 'are on y', 'f is alw', 'Glad to ', 'grey are', 'en I get', 't. I cur', 'Just ask', 'ld, I do', 'e. The d', 'borrow h', 'n mentio', ' over in', 'the endo', 'No clock', 'oney doi', 'tudy sma', 'f is alw']\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on the training data\n",
    "clf, vectorizer = train_classifier(train_texts, train_labels, (8,8))\n",
    "\n",
    "# Evaluate the classifier on the test data\n",
    "accuracy = evaluate_classifier(clf, vectorizer, test_texts, test_labels)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy:\", accuracy)\n",
    "analyze_features(10, clf, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6652456983413424\n",
      "Top 10 most significant textual features:\n",
      "['t all els', 'war noise', 'Watching ', 'e and wai', 'e braking', 'sauce but', 'gs every ', 'f a scuba', ' absorb h', 'not neces', 't all els', 'war noise', 'Watching ', 'e braking', 'any illne', 'that my d', 'e and wai', 'honest. M', 't your go', 'sauce but', 'the ridic', 'e tho and', 'es sooo m', 't all els', 'war noise', 'Watching ', 'e braking', 't your go', 'ionable b', 'that my d']\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on the training data\n",
    "clf, vectorizer = train_classifier(train_texts, train_labels, (9,9))\n",
    "\n",
    "# Evaluate the classifier on the test data\n",
    "accuracy = evaluate_classifier(clf, vectorizer, test_texts, test_labels)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy:\", accuracy)\n",
    "analyze_features(10, clf, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
