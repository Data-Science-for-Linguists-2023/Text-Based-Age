{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Reddit Dataset\n",
    "\n",
    "https://nbviewer.org/github/Data-Science-for-Linguists-2023/Text-Based-Age-Recognition/blob/main/notebooks/data_analysis/final/reddit_final.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What happened to my comment....it was soo good...</td>\n",
       "      <td>te</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A shit ton of censorship. And I don't mean \"de...</td>\n",
       "      <td>te</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wasn't aware of the drama between /r/askmen an...</td>\n",
       "      <td>te</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nice username  I too am from Finland</td>\n",
       "      <td>te</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Your comment was on the [other post]( lol</td>\n",
       "      <td>te</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64861</th>\n",
       "      <td>And, after 10 years of marriage, you can get 5...</td>\n",
       "      <td>th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64862</th>\n",
       "      <td>Yes. Thank you for this response. I don’t view...</td>\n",
       "      <td>th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64863</th>\n",
       "      <td>Better hope that you're contacted before someo...</td>\n",
       "      <td>th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64864</th>\n",
       "      <td>Thank you for this question. I also find mysel...</td>\n",
       "      <td>th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64865</th>\n",
       "      <td>Yes. Being able to consider working part-time ...</td>\n",
       "      <td>th</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64866 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text age\n",
       "0      What happened to my comment....it was soo good...  te\n",
       "1      A shit ton of censorship. And I don't mean \"de...  te\n",
       "2      Wasn't aware of the drama between /r/askmen an...  te\n",
       "3                   Nice username  I too am from Finland  te\n",
       "4              Your comment was on the [other post]( lol  te\n",
       "...                                                  ...  ..\n",
       "64861  And, after 10 years of marriage, you can get 5...  th\n",
       "64862  Yes. Thank you for this response. I don’t view...  th\n",
       "64863  Better hope that you're contacted before someo...  th\n",
       "64864  Thank you for this question. I also find mysel...  th\n",
       "64865  Yes. Being able to consider working part-time ...  th\n",
       "\n",
       "[64866 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_pickle('../../../data_samples/reddit_samples/all.pkl')\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Vectorier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now more or less in it's final form."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the main vectorizer and classifier. We might make changes to these, but for now, we're keeping it all in one place for covenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def train_classifier(texts, labels, ngrams):\n",
    "    # create a CountVectorizer with character-based bigrams\n",
    "    vectorizer = CountVectorizer(analyzer='char', ngram_range=ngrams, lowercase=False, stop_words=None)\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    # train the classifier and return it\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X, labels)\n",
    "    return clf, vectorizer\n",
    "\n",
    "def train_word_classifier(texts, labels):\n",
    "    # create a CountVectorizer with words\n",
    "    vectorizer = CountVectorizer(lowercase=False, stop_words=None)\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    # train the classifier and return it\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X, labels)\n",
    "    return clf, vectorizer\n",
    "\n",
    "def predict_age_group(classifier, vectorizer, new_text):\n",
    "    # take in a classifier as input and return the prediction\n",
    "    new_X = vectorizer.transform([new_text])\n",
    "    predicted_age_group = classifier.predict(new_X)\n",
    "    return predicted_age_group\n",
    "\n",
    "def evaluate_classifier(classifier, vectorizer, test_texts, test_labels):\n",
    "    # transform the test data\n",
    "    X_test = vectorizer.transform(test_texts)\n",
    "    # predict the age group and return score\n",
    "    predicted_age_groups = classifier.predict(X_test)\n",
    "    return accuracy_score(test_labels, predicted_age_groups)\n",
    "\n",
    "\n",
    "def analyze_features(N, clf, vec):\n",
    "    feature_names = list(vec.vocabulary_.keys())\n",
    "    log_prob = clf.feature_log_prob_\n",
    "    top_N_features = []\n",
    "    for i in range(clf.classes_.shape[0]):\n",
    "        top_N_indices = log_prob[i].argsort()[::-1][:N]\n",
    "        top_N_features.extend([feature_names[idx] for idx in top_N_indices])\n",
    "    print(\"Top {} most significant textual features:\".format(N))\n",
    "    print(top_N_features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the analysis in the `../draft/` folder, we have determined that some preprocessing helps, but not all the way (with lowercase, stemming, lemmatizing, etc.). This also helps to an extent to get the non-english text out, or at least, non-english characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_texts(texts):\n",
    "    \"\"\"\n",
    "    Cleans the given text by removing non-English characters and punctuation.\n",
    "    \"\"\"\n",
    "    # Keep only English characters and punctuation\n",
    "    text = [re.sub(r'[^a-zA-Z\\s\\.,?!]', '', text) for text in texts]\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = preprocess_texts(list(data['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What happened to my comment....it was soo good....  so ima just repeat myself  U callin yer selfs D O G S eh?',\n",
       " 'A shit ton of censorship. And I dont mean dem libtards takin muh free spheech kind of censorship. Basically if you disagree with a commenter, and reply stating a counter, your comments will be removed. Or even factual fucking errors are counted as invalidating.  Extreme example   is  and you just got to accept that  Its actually  but i get what youre saying  Your comment was removed for Invalidation.',\n",
       " 'Wasnt aware of the drama between raskmen and rAskWomen, and yet hearing about it now is completely unsurprising.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(data['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['te', 'te', 'te']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a function to drop text that's too short, and if there aren't any alphabetical bits in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def drop_short_text(text, labels, min_length=5):\n",
    "    \"\"\"\n",
    "    Drop elements from `text` and `labels` lists where the length of `text` is less than `min_length`\n",
    "    or where `text` only contains punctuation or is empty\n",
    "    \"\"\"\n",
    "    filtered_text = []\n",
    "    filtered_labels = []\n",
    "    for i in range(len(text)):\n",
    "        if len(text[i]) < min_length or all(char in string.punctuation or char.isspace() for char in text[i]):\n",
    "            # check if text is too short or only contains punctuation or whitespace\n",
    "            continue  # skip to next iteration if true\n",
    "        if not any(c.isalpha() for c in text[i]):\n",
    "            # check if text has at least one alphabet character\n",
    "            continue  # skip to next iteration if false\n",
    "        filtered_text.append(text[i])\n",
    "        filtered_labels.append(labels[i])\n",
    "    return filtered_text, filtered_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64866\n",
      "64866\n"
     ]
    }
   ],
   "source": [
    "print(len(preprocessed))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, labels = drop_short_text(preprocessed, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64507\n",
      "64507\n"
     ]
    }
   ],
   "source": [
    "print(len(text))\n",
    "print(len(labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, looks like we filtered out a good bit. Now, let's split it into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(text, labels, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoW\n",
    "\n",
    "We try the BoW approach to get the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7052394977522864\n",
      "Top 10 most significant textual features:\n",
      "['Pratchetts', 'knockout', 'skipping', 'combines', 'Urban', 'Hongkonger', 'simulator', 'adjustments', 'OOP', 'savoured', 'Pratchetts', 'knockout', 'skipping', 'combines', 'simulator', 'adjustments', 'Hongkonger', 'Urban', 'savoured', 'dialect', 'Pratchetts', 'knockout', 'skipping', 'combines', 'simulator', 'savoured', 'Urban', 'adjustments', 'dialect', 'Hongkonger']\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on the training data\n",
    "clf, vectorizer = train_word_classifier(train_texts, train_labels)\n",
    "\n",
    "# Evaluate the classifier on the test data\n",
    "accuracy = evaluate_classifier(clf, vectorizer, test_texts, test_labels)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "analyze_features(10, clf, vectorizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6013021237017516\n",
      "Top 10 most significant textual features:\n",
      "['dA', 'up', '\\xa0r', 'ca', 'Ax', 'Px', 'Ee', 'OB', '.u', 'su', 'dA', 'up', '\\xa0r', 'ca', 'Ax', 'Px', '.u', 'OB', 'Ee', 'jv', 'dA', 'up', '\\xa0r', 'ca', 'Px', 'Ax', '.u', 'OB', 'Ee', 'su']\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on the training data\n",
    "clf, vectorizer = train_classifier(train_texts, train_labels, (2,2))\n",
    "\n",
    "# Evaluate the classifier on the test data\n",
    "accuracy = evaluate_classifier(clf, vectorizer, test_texts, test_labels)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy:\", accuracy)\n",
    "analyze_features(10, clf, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6686560223221206\n",
      "Top 10 most significant textual features:\n",
      "['! Y', 'GAN', 'vip', 'Thi', 'Tzu', 'ean', 'TOL', 'e,p', 'lfS', 'oo ', '! Y', 'GAN', 'vip', 'e,p', 'Thi', 'TOL', 'Tzu', 'ean', 'lfS', 'lyr', '! Y', 'GAN', 'vip', 'e,p', 'Thi', 'Tzu', 'ean', 'lfS', 'TOL', 'LYR']\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on the training data\n",
    "clf, vectorizer = train_classifier(train_texts, train_labels, (3,3))\n",
    "\n",
    "# Evaluate the classifier on the test data\n",
    "accuracy = evaluate_classifier(clf, vectorizer, test_texts, test_labels)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy:\", accuracy)\n",
    "analyze_features(10, clf, vectorizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.696248643621144\n",
      "Top 10 most significant textual features:\n",
      "['ns t', ' Uno', 'up.c', ' npc', 'YESS', 'heel', 'g, y', 'ue f', 'fo. ', 'qrst', 'ns t', ' Uno', 'up.c', 'heel', ' npc', 'YESS', 'g, y', ' mod', 'ue f', 'fo. ', 'ns t', ' Uno', 'heel', 'up.c', ' npc', 'YESS', 'g, y', 'd I?', 'fo. ', 'ue f']\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on the training data\n",
    "clf, vectorizer = train_classifier(train_texts, train_labels, (4,4))\n",
    "\n",
    "# Evaluate the classifier on the test data\n",
    "accuracy = evaluate_classifier(clf, vectorizer, test_texts, test_labels)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy:\", accuracy)\n",
    "analyze_features(10, clf, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7007440706867153\n",
      "Top 10 most significant textual features:\n",
      "['ay. y', 'A foc', 'rong ', 'sy, a', 'Elize', 'amn n', 't fit', 'CY as', 'te Wa', 'ght h', 'ay. y', 'A foc', 'sy, a', 'rong ', 'Elize', 'ght h', 'try a', 'ned e', 'tucki', 'void.', 'ay. y', 'A foc', 'sy, a', 'rong ', 'ght h', 'Elize', 'try a', 'tucki', 'void.', 'ia an']\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on the training data\n",
    "clf, vectorizer = train_classifier(train_texts, train_labels, (5,5))\n",
    "\n",
    "# Evaluate the classifier on the test data\n",
    "accuracy = evaluate_classifier(clf, vectorizer, test_texts, test_labels)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy:\", accuracy)\n",
    "analyze_features(10, clf, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6982638350643311\n",
      "Top 10 most significant textual features:\n",
      "['he ase', 'f my o', 'ut sim', 'e I sh', 'me st ', 'ly. Ke', 'iroman', 'o pres', ' grann', 'ad pro', 'he ase', 'e I sh', 'me st ', 'ad pro', 'o pres', 'f my o', 'ut sim', 'ns? Li', 'ly. Ke', '.You c', 'he ase', 'e I sh', 'ad pro', 'o pres', 'me st ', 'ut sim', 'f my o', 'ns? Li', 'euroty', 'ge giv']\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on the training data\n",
    "clf, vectorizer = train_classifier(train_texts, train_labels, (6,6))\n",
    "\n",
    "# Evaluate the classifier on the test data\n",
    "accuracy = evaluate_classifier(clf, vectorizer, test_texts, test_labels)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy:\", accuracy)\n",
    "analyze_features(10, clf, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6902030692915827\n",
      "Top 10 most significant textual features:\n",
      "[' two fr', 'generat', 'hat , w', 'red wor', ' say pp', ' lmao n', 'op. Im ', 'ilure. ', ' good P', 'l. some', 'generat', ' two fr', 'red wor', 'y Manag', 're a gr', ' say pp', ' i assu', 'l. some', 'h STDs ', ' lmao n', 'generat', 'irl, th', 'lex I k', ' two fr', 'y Manag', 'a. she ', 'red wor', 're a gr', 'accddsu', 'per fri']\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on the training data\n",
    "clf, vectorizer = train_classifier(train_texts, train_labels, (7,7))\n",
    "\n",
    "# Evaluate the classifier on the test data\n",
    "accuracy = evaluate_classifier(clf, vectorizer, test_texts, test_labels)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy:\", accuracy)\n",
    "analyze_features(10, clf, vectorizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/varunv/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy: 0.6889629514803907\n",
      "Decision Tree accuracy: 0.5234072236862501\n",
      "Random Forest accuracy: 0.6319175321655557\n",
      "SVM accuracy: 0.6685785149589211\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Vectorize the text data with Bag-of-Words\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_texts)\n",
    "X_test = vectorizer.transform(test_texts)\n",
    "\n",
    "# Train and evaluate Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, train_labels)\n",
    "lr_accuracy = lr.score(X_test, test_labels)\n",
    "\n",
    "# Train and evaluate Decision Tree\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, train_labels)\n",
    "dt_accuracy = dt.score(X_test, test_labels)\n",
    "\n",
    "# Train and evaluate Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, train_labels)\n",
    "rf_accuracy = rf.score(X_test, test_labels)\n",
    "\n",
    "# Train and evaluate Support Vector Machine\n",
    "svm = SVC()\n",
    "svm.fit(X_train, train_labels)\n",
    "svm_accuracy = svm.score(X_test, test_labels)\n",
    "\n",
    "# Print the accuracy scores\n",
    "print(f\"Logistic Regression accuracy: {lr_accuracy}\")\n",
    "print(f\"Decision Tree accuracy: {dt_accuracy}\")\n",
    "print(f\"Random Forest accuracy: {rf_accuracy}\")\n",
    "print(f\"SVM accuracy: {svm_accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like I'm not really getting too much out of the other models.\n",
    "\n",
    "I tried it on the optimal # of N-grams for a many hours and it failed to run, but I doubt that it's going to get a lot better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
